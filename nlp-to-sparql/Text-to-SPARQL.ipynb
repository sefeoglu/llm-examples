{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f72c825f",
      "metadata": {
        "id": "f72c825f"
      },
      "source": [
        "# Definition of the project"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
        "Use the following format:\n",
        "\n",
        "Question: \"Question here\"\n",
        "\n",
        "SPARQLQuery: \"SQL Query to run\"\n",
        "\n",
        "SPARQLResult: \"Result of the SQLQuery\"\n",
        "\n",
        "\n",
        "Answer: \"Final answer here\"\n",
        "\n",
        "Only use the following tables:"
      ],
      "metadata": {
        "id": "DF7TvYypb7C2"
      },
      "id": "DF7TvYypb7C2"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "JMzp7rNEbp7-",
        "outputId": "34fc1dee-54eb-4fa4-82b1-12fab65c56be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JMzp7rNEbp7-",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4832696",
      "metadata": {
        "id": "f4832696"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1595cd3f",
      "metadata": {
        "id": "1595cd3f"
      },
      "outputs": [],
      "source": [
        "#define the libraries here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c098b1f3",
      "metadata": {
        "id": "c098b1f3"
      },
      "outputs": [],
      "source": [
        "from transformers import LlamaForCausalLM, LlamaTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "eDY_mWfjfFwJ"
      },
      "id": "eDY_mWfjfFwJ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Data"
      ],
      "metadata": {
        "id": "RV2tnwSme-HY"
      },
      "id": "RV2tnwSme-HY"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"questions.json\", \"r\") as fquestions:\n",
        "  questions = json.load(fquestions)\n",
        "questions = questions[\"questions\"]"
      ],
      "metadata": {
        "id": "rBKgE-RMfBVf"
      },
      "id": "rBKgE-RMfBVf",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"answers.json\",\"r\") as fanswers:\n",
        "  answers = json.load(fanswers)"
      ],
      "metadata": {
        "id": "3OkurDPCfjRP"
      },
      "id": "3OkurDPCfjRP",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = answers[\"answers\"]\n"
      ],
      "metadata": {
        "id": "HRdxH6RPsqmQ"
      },
      "id": "HRdxH6RPsqmQ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fe7f235e",
      "metadata": {
        "id": "fe7f235e"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <s>[INST] <<SYS>>\n",
        "# System prompt\n",
        "# <</SYS>>\n",
        "\n",
        "# User prompt [/INST] Model answer </s>"
      ],
      "metadata": {
        "id": "DD80vK7BKIOA"
      },
      "id": "DD80vK7BKIOA",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del answer_str\n",
        "del system_prompt\n",
        "del user_prompt\n",
        "del model_ans"
      ],
      "metadata": {
        "id": "P7Xv2XOzSOp0"
      },
      "id": "P7Xv2XOzSOp0",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a prompt from training data\n",
        "train_prompts = []\n",
        "answer_list = []\n",
        "\n",
        "for i, question in enumerate(questions):\n",
        "  question_string = question[\"question\"][\"string\"]\n",
        "  paraphrased_question = question[\"paraphrased_question\"][\"string\"]\n",
        "  query = question[\"query\"][\"sparql\"]\n",
        "  entities = question[\"entities\"][0]\n",
        "  relations = question[\"relations\"][0]\n",
        "  for answer in answers:\n",
        "    if \"results\" in answer[\"answer\"].keys():\n",
        "      for answer  in answer[\"answer\"][\"results\"][\"bindings\"]:\n",
        "        if \"answer\" in answer.keys():\n",
        "          answer_list.append(answer[\"answer\"][\"value\"])\n",
        "\n",
        "  answer_str = \" \".join(answer_list)\n",
        "  system_prompt = \"The natural langue question: \" + question_string +\"\\n, and the paraphrased question: \" + paraphrased_question+  \"\\n   the entity in questions is \" + entities + \"\\n the relation are \" + relations\n",
        "\n",
        "  user_prompt =  \" Its SPARQL query is  \" + query\n",
        "  model_ans = \"Answers of the SPARQL query are \" +answer_str+\" when it was run\"\n",
        "  prompt = \"<s> [INST] <<SYS>>\"+system_prompt+\"<</SYS>>\\n\"+user_prompt+\" [/INST] \"+ model_ans+\" </s>\"\n",
        "\n",
        "  train_prompts.append(prompt)\n",
        "  del answer_str\n",
        "  del system_prompt\n",
        "  del user_prompt\n",
        "  del model_ans\n"
      ],
      "metadata": {
        "id": "uKw3DFXUJxUH"
      },
      "id": "uKw3DFXUJxUH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets\n",
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "f_6f0_PNJrg8"
      },
      "id": "f_6f0_PNJrg8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import re\n",
        "\n",
        "# Load the dataset\n",
        "# dataset = load_dataset('timdettmers/openassistant-guanaco')\n",
        "\n",
        "# # Shuffle the dataset and slice it\n",
        "# dataset = dataset['train'].shuffle(seed=42).select(range(1000))\n",
        "\n",
        "# # Define a function to transform the data\n",
        "# def transform_conversation(example):\n",
        "#     conversation_text = example['text']\n",
        "#     segments = conversation_text.split('###')\n",
        "\n",
        "#     reformatted_segments = []\n",
        "\n",
        "#     # Iterate over pairs of segments\n",
        "#     for i in range(1, len(segments) - 1, 2):\n",
        "#         human_text = segments[i].strip().replace('Human:', '').strip()\n",
        "\n",
        "#         # Check if there is a corresponding assistant segment before processing\n",
        "#         if i + 1 < len(segments):\n",
        "#             assistant_text = segments[i+1].strip().replace('Assistant:', '').strip()\n",
        "\n",
        "#             # Apply the new template\n",
        "#             reformatted_segments.append(f'<s>[INST] {human_text} [/INST] {assistant_text} </s>')\n",
        "#         else:\n",
        "#             # Handle the case where there is no corresponding assistant segment\n",
        "#             reformatted_segments.append(f'<s>[INST] {human_text} [/INST] </s>')\n",
        "\n",
        "#     return {'text': ''.join(reformatted_segments)}\n",
        "\n",
        "\n",
        "# Apply the transformation\n",
        "transformed_dataset = dataset.map(transform_conversation)\n"
      ],
      "metadata": {
        "id": "q_1Uum4iJs9g"
      },
      "id": "q_1Uum4iJs9g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dd00519",
      "metadata": {
        "id": "4dd00519"
      },
      "outputs": [],
      "source": [
        "\n",
        "transformed_dataset.push_to_hub(\"guanaco-llama2-1k\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "frIt8GRIs17N"
      },
      "id": "frIt8GRIs17N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c2d9bbdf",
      "metadata": {
        "id": "c2d9bbdf"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cee130fb",
      "metadata": {
        "id": "cee130fb"
      },
      "outputs": [],
      "source": [
        "# https://huggingface.co/blog/llama2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd5ac5c5",
      "metadata": {
        "id": "dd5ac5c5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}